# data-wrangling-studies-m10
Repositório de estudos em Data Wrangling (pré-processamento de dados) com Python 🐍. Exercícios práticos do meu curso de Ciência de Dados, aplicando técnicas como codificação categórica, tratamento de missing values e padronização. Foco em pandas, NumPy e scikit-learn.

---
Aqui está uma versão revisada do seu `README.md`, com ajustes para maior clareza, organização e tom pessoal (já que é um portfólio de estudos). Também corrigi pequenos erros de formatação e o e-mail no final:

---

# 📊 Portfólio de Estudos: Preparação de Dados para Ciência de Dados

**Bem-vindo(a) ao meu repositório de exercícios práticos de preparação de dados!** 👨‍💻  
*(Projetos replicados como parte do meu curso de Ciência de Dados, com fins de aprendizado e portfólio)*

---

## 🎯 Objetivo
Este repositório documenta **meu processo de aprendizado** em técnicas essenciais de preparação de dados, com exemplos reaplicáveis e comentados. Os projetos foram desenvolvidos como parte de um curso, mas organizados aqui para:  
✔ Consolidar meu conhecimento  
✔ Demonstrar habilidades técnicas  
✔ Oferecer referências para outros estudantes  

---

## 🛠️ Tecnologias Utilizadas
| Biblioteca/Ferramenta | Aplicação Principal |
|-----------------------|---------------------|
| **pandas** | Manipulação de DataFrames, tratamento de dados faltantes |
| **numpy** | Transformações matemáticas e operações vetoriais |
| **scipy.stats** | Estatísticas avançadas (ex: Box-Cox) |
| **scikit-learn** | Codificação de categorias e padronização |

---

## 🚀 Como Usar
### 1. Clone o repositório
```bash
git clone https://github.com/seu-usuario/data-prep-portfolio.git
cd data-prep-portfolio
```

### 2. Configure o ambiente (recomendado)
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
.\venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### 3. Explore os projetos
Cada pasta contém um Jupyter Notebook ou script com:  
- Explicações passo a passo  
- Código comentado  
- Exemplos de input/output  

---

## 📂 Estrutura dos Projetos
### 1. **Inspeção Inicial dos Dados**  
*(`pandas` + visualizações básicas)*  
✔ Análise de estrutura e metadados  
✔ Detecção de valores nulos/duplicados  

### 2. **Codificação de Categóricas**  
*(`sklearn.preprocessing`)*  
✔ Comparação entre One-Hot vs. Ordinal Encoding  
✔ Casos de uso para cada técnica  

### 3. **Transformações Numéricas**  
*(`numpy` + `scipy.stats`)*  
✔ Log-transform para dados assimétricos  
✔ Box-Cox para normalização  

### 4. **Tratamento de Dados Faltantes**  
*(`pandas` avançado)*  
✔ Estratégias para imputação  
✔ Impacto na análise  

### 5. **Padronização de Dados**  
*(`sklearn.preprocessing`)*  
✔ Quando usar Min-Max vs. StandardScaler  
✔ Exemplos com datasets reais  

---

## 🤝 Contribuições e Feedback
Sou um estudante em evolução! Se você:  
🔹 Encontrar bugs ou sugestões de melhoria  
🔹 Tiver dicas para otimizar os códigos  
🔹 Quiser discutir casos de uso  

Fique à vontade para:  
- Abrir uma **issue**  
- Enviar um **pull request**  

---

## 📜 Licença
Códigos sob licença **MIT** (para projetos educacionais).  
*Dados utilizados podem ter licenças específicas — verifique os arquivos originais.*

---

## 📬 Contato
**E-mail:** Artymente@outlook.com.br  

---

🚀 **"Dados bem preparados são a base de qualquer análise eficiente!"**  
*(Repositório em constante atualização conforme aprendo novas técnicas)*  
